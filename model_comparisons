import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.svm import SVC

np.random.seed(0)

## Split testing data from training data in addition to test data bc test data has no true values to train models
## Scaled input data (both training & test) for models like SVMs and Neural Networks where normalizing data boosts performance
## Also polynomialized inputs for linear models like Logit where polynomial features also helps capture nonlinear patterns 
## Defined class method outputs to class variables so fitting/evaluation functions don't need to constantly be called when
## Calling get_model_evals, find_best_model and predict functions separately, as each GridSearch takes a few mins 
 
class FindBestModel():

    def __init__(self) -> None:
        training_data = pd.read_csv('train.csv').set_index('id')    
        self.test_data = pd.read_csv('test.csv').set_index('id')
        x = training_data.iloc[:,:-1]
        y = training_data.iloc[:,-1]
        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(x, y, random_state=0)
            
        scaler = MinMaxScaler()
        self.X_train_scaled = scaler.fit_transform(self.X_train)
        self.X_test_scaled = scaler.fit_transform(self.X_test)
        self.test_scaled = scaler.fit_transform(self.test_data)
        
        poly = PolynomialFeatures(degree=2)
        self.X_train_poly_scaled = poly.fit_transform(self.X_train_scaled)
        self.X_test_poly_scaled = poly.fit_transform(self.X_test_scaled)
        self.test_poly_scaled = poly.fit_transform(self.test_scaled)

        self.models = None
        self.model_evals = []
        self.best_model = None


    ## Created iterable of fitted objects to automate GridSearch over all models
    ## MLPClassifier default max_iter = 200 needed to be increased to yield proper fit  
    def fit_models(self):
        self.models = [
            {'model': LogisticRegression().fit(self.X_train_poly_scaled, self.y_train),
            'params': {'penalty':['l1','l2'],'C':[0.1,1,10],'solver':['liblinear']}, 'x_test': self.X_test_poly_scaled},
            {'model': SVC(random_state=0).fit(self.X_train_scaled, self.y_train),
            'params': {'kernel':['poly', 'linear'],'gamma':[1,10],'C':[1,10]}, 'x_test': self.X_test_scaled},
            {'model': MLPClassifier(random_state=0, max_iter=10000).fit(self.X_train_scaled, self.y_train),
            'params': {'hidden_layer_sizes':[1,10],'solver':['lbfgs'],'alpha':[0.01,1],'activation':['tanh','relu']}, 'x_test': self.X_test_scaled},
            {'model': GaussianNB().fit(self.X_train, self.y_train),'params': {'priors': [None]}, 'x_test': self.X_test},
            {'model': KNeighborsClassifier().fit(self.X_train, self.y_train),
            'params': {'n_neighbors':[1,10,100],'weights':['uniform','distance'],'algorithm':['auto','ball_tree','kd_tree']}, 'x_test': self.X_test},
            {'model': DecisionTreeClassifier(random_state = 0).fit(self.X_train, self.y_train),
            'params': {'max_depth':[2,4,6,10],'splitter':['best','random']}, 'x_test': self.X_test},
            {'model': RandomForestClassifier(random_state = 0).fit(self.X_train, self.y_train),
            'params': {'max_features':[2,6],'n_estimators':[100,500],'n_jobs':[1,5]}, 'x_test': self.X_test},
            {'model': GradientBoostingClassifier(random_state=0).fit(self.X_train_scaled, self.y_train),
            'params': {'n_estimators':[100,500],'max_depth':[2,6],'learning_rate':[0.001,1]}, 'x_test': self.X_test}
        ]
    

    ## Assert ensures model fit class method precedes model eval as GridSearch requires fitted model objects 
    ## Extracts just roc_auc score (to optimize over) and best model parameters (only parameters we will use if we choose the model)  
    def get_model_evals(self):
        assert len(self.models) > 1, 'No models to calculate roc-auc'
        for model in self.models:
            results = GridSearchCV(model['model'],param_grid=model['params'],scoring='roc_auc',cv=5).fit(model['x_test'], self.y_test)
            self.model_evals.append({'ob': results.best_estimator_, 'roc_auc_score': results.best_score_})


    ## Assert ensures model eval method precedes model selection as we optimize over eval's roc_auc score
    def find_best_model(self):
        assert len(self.model_evals) > 1, 'No models to get best'
        self.best_model = max((model_score['roc_auc_score'], model_score) for model_score in self.model_evals)[1]
 

    ## Assert ensures model selection method precedes prediction as we need to know which model we are predicting with
    ## Linear models are fitted over normalized/polynomialized data, so we need to check if our model here needs also for testing data
    def best_model_predict(self):
        assert self.best_model is not None, 'No model to predict'
        if any(model in str(self.best_model['ob']) for model in ['SVC', 'MLP']): return self.best_model['ob'].predict(self.test_scaled)
        elif 'Logistic' in str(self.best_model['ob']): return self.best_model['ob'].predict(self.test_poly_scaled)
        else: return self.best_model['ob'].predict(self.test_data)


model_selector = FindBestModel()
model_selector.fit_models()
model_selector.get_model_evals()
model_selector.find_best_model()
print(model_selector.models)
print(model_selector.model_evals)
print(model_selector.best_model)
print(model_selector.best_model_predict())
